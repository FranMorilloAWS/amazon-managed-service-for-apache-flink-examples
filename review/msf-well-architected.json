{
  "schemaVersion": "2021-11-01",
  "name": "Well-Architected Lens for Amazon Managed Service for Apache Flink ",
  "description": "Use this template to help decide whether or not your Apache Flink applications on Managed Service for Apache Flink is considered well-architected according to the best practices.",
  "pillars": [
    {
      "id": "dev_and_testing",
      "name": "Development and Testing",
      "questions": [
        {
          "id": "dev_and_testing_q1",
          "title": "Have you developed your Apache Flink application locally and seen a successful execution of sample data?",
          "description": "Developing locally is a critical piece of understanding how your application works, and if it will work well at scale.",
          "helpfulResource": {
            "displayText": "For more information in how to develop your Apache Flink applications locally, click the link provided",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/examples-getting-started-locally-flink.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Work to get your application set up locally in order to quickly iterate and develop your applications: https://docs.aws.amazon.com/managed-flink/latest/java/examples-getting-started-locally-flink.html"
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q2",
          "title": "Have you integration tested your application to see that it successfully connects to sources and sinks?",
          "description": "Testing your application's connectivity to sources and sinks will help ensure expected results when starting up the application.",
          "helpfulResource": {
            "displayText": "For more information in how to integration test your Apache Flink applications locally, click the link provided",
            "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/testing/#testing-flink-jobs"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "It is imperative that before pushing code to production, the connections to external data sources are functional. This can prevent a loss of data and other issues within an Apache Flink application."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q3",
          "title": "Have you performance tested your application for a minimum of 5 days?",
          "description": "Sufficient testing includes performance testing for longer periods of time. 5 days, or enough time to see the patterns that emerge in your application is considered a best practice.",
          "helpfulResource": {
            "displayText": "For more information in how to performance test your Apache Flink applications, click the link provided",
            "url": "https://github.com/aws-samples/amazon-kinesis-data-analytics-flink-benchmarking-utility"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Apache Flink applications perform differently over the short term and long term. By performance testing the application over longer periods of time, the behavior of the application becomes more predictable."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q4",
          "title": "Is checkpoint size & duration steady in the long term? (hours/days)",
          "description": "A manageable application includes manageable state and checkpoint duration. Ensure that your checkpoints are not ever-increasing and getting cleared out by garbage collection over longer periods of time.",
          "helpfulResource": {
            "displayText": "For more information on monitoring and troubleshooting checkpoints, see the link provided.",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/troubleshooting-checkpoints.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Checkpoint growth in an unbounded manner can be detrimental to the performance of your application. Ensure that the size and growth of your checkpoints are in line with what you would expect from the data stored. Additionally, longer checkpoints can cause backpressure and slowness in processing data. Check the following blog for more information: https://aws.amazon.com/blogs/big-data/part-1-optimize-checkpointing-in-your-amazon-managed-service-for-apache-flink-applications-with-buffer-debloating-and-unaligned-checkpoints/"
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q5",
          "title": "Have you performance tested your application with realistic data mirroring production traffic, key cardinality and distribution?",
          "description": "In order to understand your application's performance, send realistic data through during performance tests to realistically simulate production traffic.",
          "helpfulResource": {
            "displayText": "You can use Managed Service for Apache Flink Studio, another Apache Flink application using the RichParallelSourceFunction, JMeter or another testing mechanism to simulate realistic traffic.",
            "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/connectors/datastream/datagen/"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Testing with data that reflects your actual production use case can help understand the behavior of your application and how it will perform in reality."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q6",
          "title": "Does your code have unit testing for functions you have defined? (UDFs, ProcessFunctions, etc)",
          "description": "Unit Testing can help uncover issues before they arise whenever code is changed.",
          "helpfulResource": {
            "displayText": "It is recommended to unit test your functions to ensure your application is functioning as expected.",
            "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/testing/"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Implement unit tests in your application code according to Flink documentation of testing protocol."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q7",
          "title": "Does your application use ProcessFunction APIs and manage state manually? Does it need to do this?",
          "description": "The ProcessFunction API for Apache Flink is a low-level API giving the user access to things like state, timers and more control over the Apache Flink application's behavior. This control, carefully wielded, can be very powerful. Only use this API level if you absolutely need to, otherwise stick to higher-level APIs.",
          "helpfulResource": {
            "displayText": "Using lower level APIs like the ProcessFunction APIs for Apache Flink can lead to unexpected results and accumulation of state if not designed properly.",
            "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/state/"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "The Process Function APIs require great care and testing—if you need to manually manipulate state data, ensure you are effectively cleaning it out with StateTTLConfig, timers, and proper state management techniques."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "The Process Function APIs require great care and testing—if you need to manually manipulate state data, ensure you are effectively cleaning it out with StateTTLConfig, timers, and proper state management techniques."
              }
            }
          ],
          "riskRules": [
            {
              "condition": "default",
              "risk": "NO_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q8",
          "title": "Do all operators have unique IDs assigned?",
          "description": "Apache Flink operator IDs are automatically assigned if not specified manually. These IDs are used to scope the state of each operator when performing stateful operations. Manually setting operator IDs gives more control and predictability when accessing state and restoring state.",
          "helpfulResource": {
            "displayText": "Assigning operator IDs can help Apache Flink restore from savepoints / snapshots when updating or scaling the applications.",
            "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/ops/state/savepoints/#:~:text=Assigning%20Operator%20IDs&text=These%20IDs%20are%20used%20to%20scope%20the%20state%20of%20each%20operator.&text=If%20you%20do%20not%20specify,these%20IDs%20do%20not%20change."
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": " Assigning Operator IDs manually for each operator can help when taking savepoints and recovering from those savepoints. Operator IDs are generated automatically otherwise, and are unpredictable. When Flink tries to restore savepoints back to the application, these Operator IDs are used to inform the framework about which operator gets which state. Failure to do this can result in improper state restoration."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q9",
          "title": "Did you enable RocksDB metrics in development to monitor state access, size and latency?",
          "description": "Enabling metrics for RocksDB locally can help with visibility of your Apache Flink state and identify issues with RocksDB before deploying to Managed Service for Apache Flink",
          "helpfulResource": {
            "displayText": "If you are testing locally, ensure you monitor RocksDB to see how the state is being stored and how it performs over time.",
            "url": "https://github.com/apache/flink/blob/master/flink-state-backends/flink-statebackend-rocksdb/src/main/java/org/apache/flink/contrib/streaming/state/RocksDBNativeMetricOptions.java"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Monitoring your RocksDB metrics can help ensure predictable performance over time."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "dev_and_testing_q10",
          "title": "If you are accessing external systems, have you done so under backpressure?",
          "description": "Testing your application under backpressure can help prepare for high load scenarios where operators are operating slowly, increasing memory usage and latency. Testing under backpressure can help avoid larger issues in production.",
          "helpfulResource": {
            "displayText": "Backpressured operators can cause unintended consequences if not designed properly. Test your operators under high load and backpressure to ensure stability of the upstream operators in the application.",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/troubleshooting-backpressure.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "It is recommended to test your applications under backpressure in a simulated fashion to understand how upstream operators respond to this. Ensure that data is not lost and that the application can handle temporary backpressure applied."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        }
      ]
    },
    {
      "id": "monitoring",
      "name": "Monitoring",
      "questions": [
        {
          "id": "monitoring_q1",
          "title": "Have you implemented a monitoring strategy using the metrics recommended by the Managed Service for Apache Flink best practices?",
          "description": "Monitoring the right metrics for your Apache Flink application on Managed Service for Apache Flink can help diagnose and identify potential issues in the application before they occur.",
          "helpfulResource": {
            "displayText": "For more information in how to monitor your Apache Flink applications, click the link provided",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/monitoring.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "It is crucial to implement monitoring and proper alarming of all components not only the Flink application. Otherwise you risk to miss emerging problems early on and only realize an operational event once it is fully unravelling and much harder to mitigate."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "monitoring_q2",
          "title": "Have you set practical alarms for each of the metrics recommended by Managed Service for Apache Flink Best Practices?",
          "description": "Alarming can help you respond to issues within your application such as increasing Consumer Lag, CPU utilization or Memory as they happen. Without alarms in place, the application could silently fail.",
          "helpfulResource": {
            "displayText": "For more information in how to alarm on your Apache Flink metrics, click the link provided",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/monitoring-metrics-alarms.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "It is crucial to implement proper alarming of all components not only the Flink application. Otherwise you risk to miss emerging problems early on and only realize an operational event once it is fully unravelling and much harder to mitigate."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "monitoring_q3",
          "title": "Are you logging / printing every message you receive within your Apache Flink application to a logger or the System Console?",
          "description": "Flink is optimized for high throughout and low latency, the logging subsystem is not. Logging or printing on every message can cause issues for the logging subsystem, resulting in degraded performance.",
          "helpfulResource": {
            "displayText": "For more information in how to log and trace messages in your Apache Flink application:",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/logging.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "N/A"
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "Flink is optimized for high throughout and low latency, the logging subsystem is not. In case it is really required to generate log output for every processed message, use an additional DataStream inside the Flink application and a proper sink to send the data to Amazon S3 or CloudWatch. Do not use the Java logging system for this purpose. Moreover, Managed Service for Apache Flink’ Debug Monitoring Log Level setting generates a large amount of traffic, which can create backpressure. You should only use it while actively investigating issues with the application."
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "monitoring_q4",
          "title": "Have you implemented a mechanism to monitor end-to-end latency using custom metrics?",
          "description": "Within Managed Service for Apache Flink, you have the ability to develop custom metrics within your application to generate and send custom metrics to Amazon CloudWatch.",
          "helpfulResource": {
            "displayText": "For more information in how to create custom metrics in your Managed Service for Apache Flink application:",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/monitoring-metrics-custom.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "For more information in how to create custom metrics in your Managed Service for Apache Flink application: https://docs.aws.amazon.com/managed-flink/latest/java/monitoring-metrics-custom.html"
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "default",
              "risk": "NO_RISK"
            }
          ]
        },
        {
          "id": "monitoring_q5",
          "title": "Are you monitoring the progression of your watermarks in your Apache Flink application?",
          "description": "Within Managed Service for Apache Flink, you have the ability to monitor the currentInputWatermark and currentOutputWatermark of your application. This can help showcase how watermarks are progressing, and if any data is arriving unexpectedly late.",
          "helpfulResource": {
            "displayText": "For more information in how to leverage the currentWatermark metrics:",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/best-practices.html#notebook-watermarking"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "If you are using watermark strategy, ensure you know the expected behavior of your data and when it should be considered late / how the application is progressing."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        }
      ]
    },
    {
      "id": "state_management",
      "name": "State Management",
      "questions": [
        {
          "id": "state_management_q1",
          "title": "Have you enabled bluffer debloating?",
          "description": "In version 1.14, Apache Flink introduced buffer debloating, which can be enabled to adjust in-flight data of each sub-task, based on the current throughput the sub-task is processing, and periodically reassess and readjust it.",
          "helpfulResource": {
            "displayText": "For more information on how to enable buffer debloating:",
            "url": "https://aws.amazon.com/blogs/big-data/part-1-optimize-checkpointing-in-your-amazon-managed-service-for-apache-flink-applications-with-buffer-debloating-and-unaligned-checkpoints/"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Buffer debloating could benefit your application performance by allowing for more data to be in-flight dynamically. Please see the linked blog for more information."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "Buffer debloating could benefit your application performance by allowing for more data to be in-flight dynamically. Please see the linked blog for more information."
              }
            }
          ],
          "riskRules": [
            {
              "condition": "default",
              "risk": "NO_RISK"
            }
          ]
        },
        {
          "id": "state_management_q2",
          "title": "Have you ensured checkpoints are enabled and being completed at a regular interval?",
          "description": "Checkpoints are Apache Flink's mechanism of state, storing data, offset tracking and application information in memory or in a highly-available fileystem. They are critical to making your Apache Flink application's state fault tolerant in case of failures in the Apache Flink cluster.",
          "helpfulResource": {
            "displayText": "For more information on Apache Flink checkpointing:",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/troubleshooting-checkpoints.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Without checkpoints enabled (enabled by default), your application is at risk of losing data. Please enable checkpoints on your Managed Service for Apache Flink application."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "state_management_q3",
          "title": "Have you ensured snapshots are taken at regular intervals? (using snapshots manager or other mechanism)?",
          "description": "A snapshot is the Managed Service for Apache Flink implementation of an Apache Flink Savepoint. A snapshot is a user- or service-triggered, created, and managed backup of the application state. For information about Apache Flink Savepoints, see Savepoints in the Apache Flink Documentation. Using snapshots, you can restart an application from a particular snapshot of application state.",
          "helpfulResource": {
            "displayText": "For more information on Managed Service for Apache Flink snapshots:",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/how-fault-snapshot.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "We recommend that your application create a snapshot several times a day to restart properly with correct state data. The correct frequency for your snapshots depends on your application's business logic. Taking frequent snapshots allows you to recover more recent data, but increases cost and requires more system resources. See the Snapshot Manager for Flink: https://docs.aws.amazon.com/managed-flink/latest/java/snapshot-manager.html"
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "state_management_q4",
          "title": "Are you managing state effectively by using StateTTLConfig, higher level APIs, or other mechanisms?",
          "description": "Managing state effectively is comprised of either using higher level APIs like the Table or SQL API, sticking to built-in DatatStream stateful operations like Tumbling / Sliding windows, and if using ProcessFunction APIs, clearing out state correctly with StateTTLConfig and other strategies.",
          "helpfulResource": {
            "displayText": "For more information on Managing State, see the link provided:",
            "url": "https://docs.aws.amazon.com/managed-flink/latest/java/troubleshooting-rt-stateleaks.html"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "In addition to monitoring your state, ensuring that it is effectively cleared out and not growing ever-increasingly is a key component to ensuring application stability. Please see the recommendations in the following link to improve your state management strategies: https://docs.aws.amazon.com/managed-flink/latest/java/troubleshooting-rt-stateleaks.html"
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "!choice1 && choice2",
              "risk": "HIGH_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "state_management_q5",
          "title": "Have you defined a proper Service Level Agreement (SLA) for your application (when data needs to be available in sink)? ",
          "description": "This is helpful in determining checkpoint and snapshotting intervals as some sinks require checkpointing to commit data to the destination",
          "helpfulResource": {
            "displayText": "Defining the SLA for your application is crucial to monitoring performance."
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Define your SLA for your application to ensure you are meeting the proper end-to-end latencies for your application. This can also be monitored."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "state_management_q6",
          "title": "Are you utilizing data types that allow for schema evolution within the Apache Flink state?",
          "description": "Data Types like Plain Old Java Objects (POJOs) or Avro support schema evolution out of the box. Kryo cannot be used for schema evolution.",
          "helpfulResource": {
            "displayText": "Choosing a format that supports schema evolution can help avoid situations where your state composition changes and this results in a breaking change for the application. See State Schema Evolution for more information.",
            "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/serialization/schema_evolution/"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Use a data type that supports schema evolution to avoid breaking changes if or when your state schema changes."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "HIGH_RISK"
            }
          ]
        }
      ]
    },
    {
      "id": "performanceEfficiency",
      "name": "Scaling",
      "questions": [
        {
          "id": "performanceEfficiency_q1",
          "title": "Have you orchestrated any autoscaling based on the profile of your application’s performance?",
          "description": "Managed Service for Apache Flink can be configured to autoscale based on CPU Utilization or other metrics that appear in Amazon CloudWatch.",
          "helpfulResource": {
            "displayText": "For more information in how to scale your application based on non-CPU metrics, see the link below. Please ensure that both checkpoints and snapshots are enabled in order to make full benefit of autoscaling if your application is stateful.",
            "url": "https://github.com/aws-samples/amazon-managed-service-for-apache-flink-examples/tree/main/infrastructure/AutoScaling"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Autoscaling can help your application both scale with throughput and demand, as well as optimally scale down when resources are no longer needed."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        },
        {
          "id": "performanceEfficiency_q2",
          "title": "Have you set operator parallelism as a function of application parallelism?",
          "description": "If using strict operator parallelism setting (in addition to application parallelism), it is recommended that operator parallelism be set as a function of appliaction parallelism so that it scales with the application. Example: (APPLICATION_PARALLELISM / 2). Setting this to a static number does not allow it to scale when the application scales.",
          "helpfulResource": {
            "displayText": "For more information on operator parallelism, please see the following link:",
            "url": "https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/datastream/execution/parallel/"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Setting operator parallelism to a static number does not allow it to scale when the application scales. If this is expected or intentional, this can be ignored."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "MEDIUM_RISK"
            }
          ]
        }
      ]
    },
    {
      "id": "operationalExcellence",
      "name": "CI/CD",
      "questions": [
        {
          "id": "operationalExcellence_q1",
          "title": "Do you have CI/CD Pipeline in place for your Apache Flink application?",
          "description": "A continuous integration / deployment pipeline for deploying onto Managed Service for Apache Flink can help with operations like deploying new application versions, including automated snapshots and avoiding data loss.",
          "helpfulResource": {
            "displayText": "For more information in how to implement CI/CD for your Apache Flink deployments, see the following link:",
            "url": "https://aws.amazon.com/blogs/big-data/automate-deployment-and-version-updates-for-amazon-kinesis-data-analytics-applications-with-aws-codepipeline/"
          },
          "choices": [
            {
              "id": "choice1",
              "title": "Yes",
              "improvementPlan": {
                "displayText": "Having a solid deployment strategy is vital to ensuring the stability of your Apache Flink applications in between code changes and new deployments."
              }
            },
            {
              "id": "choice2",
              "title": "No / I Don't Know",
              "improvementPlan": {
                "displayText": "N/A"
              }
            }
          ],
          "riskRules": [
            {
              "condition": "choice1 && !choice2",
              "risk": "NO_RISK"
            },
            {
              "condition": "default",
              "risk": "HIGH_RISK"
            }
          ]
        }
      ]
    }
  ]
}